{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809e1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sondrewo/Documents/graph_impact/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e05ddba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, gpt, config, max_len=31):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gpt = gpt\n",
    "        self.config = config\n",
    "        self.max_len = max_len\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: [batch, seq]\n",
    "        context_len = inputs.size(1)\n",
    "        generated = inputs\n",
    "        next_token = inputs\n",
    "        past = None\n",
    "        with torch.no_grad():\n",
    "            for step in range(self.max_len):\n",
    "                outputs = self.gpt(next_token, past_key_values=past)\n",
    "                hidden = outputs[0][:, -1]\n",
    "                past = outputs[1]\n",
    "                next_token_logits = self.lm_head(hidden)\n",
    "                next_logits, next_token = next_token_logits.topk(k=1, dim=1)\n",
    "                generated = torch.cat((generated, next_token), dim=1)\n",
    "        return generated\n",
    "\n",
    "class PathGenerator():\n",
    "    def __init__(self):\n",
    "        print(\"Load Path Generator..\")\n",
    "        lm_type = 'gpt2'\n",
    "        config = GPT2Config.from_pretrained(lm_type)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(lm_type)\n",
    "        self.tokenizer.add_tokens(['<PAD>'])\n",
    "        self.tokenizer.add_tokens(['<SEP>'])\n",
    "        self.tokenizer.add_tokens(['<END>'])\n",
    "        gpt = GPT2Model.from_pretrained(lm_type)\n",
    "        config.vocab_size = len(self.tokenizer)\n",
    "        gpt.resize_token_embeddings(len(self.tokenizer))\n",
    "        pretrain_generator_ckpt = \"../pg/commonsense-path-generator.ckpt\"\n",
    "        self.generator = Generator(gpt, config)\n",
    "        self.generator.load_state_dict(torch.load(pretrain_generator_ckpt, map_location=torch.device(\"cpu\")), strict=False)\n",
    "\n",
    "    def prepare_input(self, head_entity, tail_entity, input_len=16):\n",
    "        head_entity = head_entity.replace('_', ' ')\n",
    "        tail_entity = tail_entity.replace('_', ' ')\n",
    "        input_token = tail_entity + '<SEP>' + head_entity\n",
    "        input_id = self.tokenizer.encode(input_token, add_special_tokens=False)[:input_len]\n",
    "        input_id += [self.tokenizer.convert_tokens_to_ids('<PAD>')] * (input_len - len(input_id))\n",
    "        return torch.tensor([input_id], dtype=torch.long)\n",
    "\n",
    "    def connect_entities(self, head_entity, tail_entity):\n",
    "        gen_input = self.prepare_input(head_entity, tail_entity)\n",
    "        gen_output = self.generator(gen_input)\n",
    "        path = self.tokenizer.decode(gen_output[0].tolist(), skip_special_tokens=True)\n",
    "        path = ' '.join(path.replace('<PAD>', '').split())\n",
    "        return path[path.index('<SEP>')+6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3eccd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Path Generator..\n"
     ]
    }
   ],
   "source": [
    "PG = PathGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ca85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(x):\n",
    "        x = x.replace(\")(\", \", \")\n",
    "        return x.replace(\"(\", \"\").replace(\")\",\"\").replace(\";\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75a4f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(x):\n",
    "        original_explanation_graph = x.split(\";\")\n",
    "        head = clean_string(original_explanation_graph[0])\n",
    "        tail = clean_string(original_explanation_graph[-1])\n",
    "        #print(f\"Explanation was: {original_explanation_graph}, head is now {head}, tail is {tail}\")\n",
    "        path = PG.connect_entities(head, tail)\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da005173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"../data/dev_original.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1495367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train_original.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b559bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = [\"belief\", \"argument\", \"label\", \"explanation\"]\n",
    "df_val.columns = [\"belief\", \"argument\", \"label\", \"explanation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ed2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71add5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 2753/2764 [25:26<00:06,  1.82it/s]"
     ]
    }
   ],
   "source": [
    "new_paths = []\n",
    "for i, exp in enumerate(tqdm(df[\"explanation\"])):\n",
    "    new_paths.append(get_path(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(df, random_state=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_val, random_state=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6103ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"../data/val.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d948f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"../data/test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplaGraphs(Dataset):\n",
    "    def __init__(self, model_name, split=\"train\", use_graphs=True):\n",
    "        print(f\"Use graph explanations = {use_graphs}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        df = pd.read_csv(f\"../data/{split}.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "        premises, arguments, self.labels, explanations = df.to_numpy().T\n",
    "        self.label_converter = {\"counter\": 0, \"support\": 1}\n",
    "        self.label_inverter = {0: \"counter\", 1: \"support\"}\n",
    "        explanations = [self.clean_string(x) for x in explanations]\n",
    "        if use_graphs == True:\n",
    "            self.features = [prem + \" [SEP] \" + arg + \" [SEP] \" + exp for prem,arg,exp in zip(premises, arguments, explanations)]\n",
    "        else:\n",
    "            self.features = [prem + \" [SEP] \" + arg for prem,arg in zip(premises, arguments)]\n",
    "            \n",
    "        encodings = self.tokenizer(self.features, truncation=True, padding=True)\n",
    "        self.input_ids, self.attention_masks = encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
    "        \n",
    "    def clean_string(self, x):\n",
    "        x = x.replace(\")(\", \", \")\n",
    "        return x.replace(\"(\", \"\").replace(\")\",\"\").replace(\";\", \"\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.input_ids[idx]), torch.BoolTensor(self.attention_masks[idx]), self.label_converter[self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2710080",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ExplaGraphs(\"bert-base-uncased\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad752a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f484c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59b54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
