{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e21bb3-189f-4cb1-a6ce-12dba963655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sondrewo/Documents/graph_impact/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from stop import eng_stop_words\n",
    "from concept_net import PathRetriever\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7405b2-281c-4cc7-9a2c-3190f6d90985",
   "metadata": {},
   "source": [
    "# 1) Fuse original splits into one file for both ExplaGraphs and COPA-SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e75c4f-37f5-4834-96ef-3f090c0108cd",
   "metadata": {},
   "source": [
    "### ExplaGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58fbe76-e1d9-4825-9eb1-60e31fb6e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_val = pd.read_csv(\"../data/explagraphs/dev_original.tsv\", sep=\"\\t\", header=0)\n",
    "exp_train = pd.read_csv(\"../data/explagraphs/train_original.tsv\", sep=\"\\t\", header=0)\n",
    "exp_train.columns = [\"belief\", \"argument\", \"label\", \"gold_graph\"]\n",
    "exp_val.columns = [\"belief\", \"argument\", \"label\", \"gold_graph\"]\n",
    "exp_df = pd.concat([exp_train, exp_val], axis=0)\n",
    "exp_df['id'] = range(880, 880+len(exp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c44e7-fde6-40f1-a467-0ed6c79ad267",
   "metadata": {},
   "source": [
    "### COPA-SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7295b413-8572-43b6-90b9-87273dd98809",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_dev = pd.read_json(\"../data/copa/copa_dev_original.jsonl\", lines=True)\n",
    "copa_test = pd.read_json(\"../data/copa/copa_test_original.jsonl\", lines=True)\n",
    "copa_df = pd.concat([copa_dev, copa_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca32799-a590-4acd-88ee-1b465e598243",
   "metadata": {},
   "source": [
    "### For COPA-SSE, we keep the human annotated graph with the highest rating as the gold graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b1ba7b-62d4-4819-ba6b-24f8ed5e4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_explanations = []\n",
    "for i, row in copa_df.iterrows():\n",
    "    candidates = list(row[\"human-explanations\"])\n",
    "    best_score = 0.0\n",
    "    best_candidate = 0\n",
    "    for i, cand in enumerate(candidates):\n",
    "        score = cand[\"filtered-avg-rating\"]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_candidate = i\n",
    "    best_explanations.append(candidates[best_candidate][\"triples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e4da93-3de5-4e3b-a2dd-9081f135c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_df[\"gold_graph\"] = best_explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd54bf-7cd2-416e-956c-4ac9881222df",
   "metadata": {},
   "source": [
    "# 2) Transform gold explanations into one single format for both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f5ea7-11e2-477e-8560-67fe9591a5e3",
   "metadata": {},
   "source": [
    "The triple format of COPA-SSE is neater, transform the ExplaGraphs format into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab224e1d-9a01-4c40-9c2e-ccba0fa09067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_expla_to_triple(explanation: str):\n",
    "    print(explanation)\n",
    "    triples = explanation.split(\")(\")\n",
    "    triples = [s.strip(\"(\").strip(\")\") for s in triples]\n",
    "    new_triples = []\n",
    "    for trip in triples:\n",
    "        head, rel, tail = trip.split(\";\")\n",
    "        new_triples.append([head.strip(),rel.strip(),tail.strip()])\n",
    "    return new_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb0e1c-e44a-47cf-a8bc-0c6b3ed25acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df[\"gold_graph\"] = exp_df[\"gold_graph\"].apply(lambda x: transform_expla_to_triple(x)) #Gives long output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d69e78-bb63-4041-ae91-f515e8172e5f",
   "metadata": {},
   "source": [
    "# 3) Append graph explanations of different quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c6322",
   "metadata": {},
   "source": [
    "## 3.0) Entity Linking from Lin et al..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc530149",
   "metadata": {},
   "source": [
    "### Expla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea86b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "grounded_expla = {}\n",
    "with open(\"../expla_grounded.jsonl\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        e = json.loads(line)\n",
    "        grounded_expla[e[\"id\"]] =  e[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7368b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_paths = []\n",
    "\n",
    "for idx, row in exp_df.iterrows():\n",
    "    try:\n",
    "        x = grounded_expla[row['id']]\n",
    "    except:\n",
    "        x = []\n",
    "    el_paths.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25382928",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df[\"linked_paths\"] = el_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71041b",
   "metadata": {},
   "source": [
    "### Copa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b64be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grounded_copa = {}\n",
    "with open(\"../copa_grounded.jsonl\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        e = json.loads(line)\n",
    "        grounded_copa[e[\"id\"]] =  e[\"path\"]\n",
    "elc_paths = []\n",
    "\n",
    "for idx, row in copa_df.iterrows():\n",
    "    try:\n",
    "        x = grounded_copa[row['id']]\n",
    "    except:\n",
    "        x = []\n",
    "    elc_paths.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04aadb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_df[\"linked_paths\"] = elc_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd94421-075a-4e33-b474-effe703d1d19",
   "metadata": {},
   "source": [
    "## 3.1) Generated Paths from https://arxiv.org/abs/2005.00691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00e9368f-650d-4532-9267-8e6e68c5436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2t = None\n",
    "with open('relation2text.json') as json_file:\n",
    "    r2t = json.load(json_file)\n",
    "    r2t =  {k.lower(): v for k, v in r2t.items()}\n",
    "r2t_keys_text = [r.lower() for r in r2t.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d1c0003-f1a1-452a-9be8-0586e142186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, gpt, config, max_len=31):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gpt = gpt\n",
    "        self.config = config\n",
    "        self.max_len = max_len\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: [batch, seq]\n",
    "        context_len = inputs.size(1)\n",
    "        generated = inputs\n",
    "        next_token = inputs\n",
    "        past = None\n",
    "        with torch.no_grad():\n",
    "            for step in range(self.max_len):\n",
    "                outputs = self.gpt(next_token, past_key_values=past)\n",
    "                hidden = outputs[0][:, -1]\n",
    "                past = outputs[1]\n",
    "                next_token_logits = self.lm_head(hidden)\n",
    "                next_logits, next_token = next_token_logits.topk(k=1, dim=1)\n",
    "                generated = torch.cat((generated, next_token), dim=1)\n",
    "        return generated\n",
    "\n",
    "class PathGenerator():\n",
    "    def __init__(self):\n",
    "        print(\"Load Path Generator..\")\n",
    "        lm_type = 'gpt2'\n",
    "        config = GPT2Config.from_pretrained(lm_type)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(lm_type)\n",
    "        self.tokenizer.add_tokens(['<PAD>'])\n",
    "        self.tokenizer.add_tokens(['<SEP>'])\n",
    "        self.tokenizer.add_tokens(['<END>'])\n",
    "        gpt = GPT2Model.from_pretrained(lm_type)\n",
    "        config.vocab_size = len(self.tokenizer)\n",
    "        gpt.resize_token_embeddings(len(self.tokenizer))\n",
    "        pretrain_generator_ckpt = \"../pg/commonsense-path-generator.ckpt\" #Use an already trained model from the paper. \n",
    "        self.generator = Generator(gpt, config)\n",
    "        self.generator.load_state_dict(torch.load(pretrain_generator_ckpt, map_location=torch.device(\"cpu\")), strict=False)\n",
    "\n",
    "    def prepare_input(self, head_entity, tail_entity, input_len=16):\n",
    "        head_entity = head_entity.replace('_', ' ')\n",
    "        tail_entity = tail_entity.replace('_', ' ')\n",
    "        input_token = tail_entity + '<SEP>' + head_entity\n",
    "        input_id = self.tokenizer.encode(input_token, add_special_tokens=False)[:input_len]\n",
    "        input_id += [self.tokenizer.convert_tokens_to_ids('<PAD>')] * (input_len - len(input_id))\n",
    "        return torch.tensor([input_id], dtype=torch.long)\n",
    "\n",
    "    def connect_entities(self, head_entity, tail_entity):\n",
    "        gen_input = self.prepare_input(head_entity, tail_entity)\n",
    "        gen_output = self.generator(gen_input)\n",
    "        path = self.tokenizer.decode(gen_output[0].tolist(), skip_special_tokens=True)\n",
    "        path = ' '.join(path.replace('<PAD>', '').split())\n",
    "        \n",
    "        try:\n",
    "            path = path[path.index('<SEP>')+6:]\n",
    "        except ValueError as e:\n",
    "            return None\n",
    "        entities = path.split(\" \")\n",
    "        final = []\n",
    "        prev_was_rel = False\n",
    "        head = \"\"\n",
    "        tail = \"\"\n",
    "        trip = []\n",
    "        trip_counter = 0\n",
    "        for i in range(0, len(entities)): #State machine to construct complete triples from the string representations in the GPT-2 output.\n",
    "            if prev_was_rel == False and entities[i].strip(\"_\") not in r2t_keys_text:\n",
    "                if head == \"\":\n",
    "                    head = entities[i]\n",
    "                else:\n",
    "                    head += \" \" + entities[i]\n",
    "            if entities[i].strip(\"_\") in r2t_keys_text:\n",
    "                trip.append(head)\n",
    "                prev_was_rel = True\n",
    "                tail = \"\"\n",
    "                head = \"\"\n",
    "                trip.append(entities[i])\n",
    "            if prev_was_rel == True and entities[i].strip(\"_\") not in r2t_keys_text:\n",
    "                if tail == \"\":\n",
    "                    tail = entities[i]\n",
    "                else:\n",
    "                    tail += \" \" + entities[i]\n",
    "                if i < len(entities)-1:\n",
    "                    if entities[i+1] in r2t_keys_text:\n",
    "                        prev_was_rel = False\n",
    "                        trip.append(tail)\n",
    "                        if len(trip[0])  == 0 and len(final) > 0:\n",
    "                            trip[0] = final[trip_counter-1][-1]\n",
    "                        final.append(trip)\n",
    "                        trip_counter += 1\n",
    "                        trip = []\n",
    "                        tail = \"\"\n",
    "                        head = \"\"\n",
    "                else:\n",
    "                    trip.append(tail)\n",
    "                    if len(trip[0])  == 0 and len(final) > 0:\n",
    "                            trip[0] = final[trip_counter-1][-1]\n",
    "                    final.append(trip)\n",
    "                    \n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe5d689e-1ca8-4a07-84ea-2aee47dc3582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Path Generator..\n"
     ]
    }
   ],
   "source": [
    "PG = PathGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369622be-05d7-4112-8825-f6dd6e8db726",
   "metadata": {},
   "source": [
    "### 3.1.1) COPA-SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5136bb9b-f80e-4df4-8989-028bbc5158ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [14:57<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "generated_paths_copa = []\n",
    "for i, exp in enumerate(tqdm(copa_df[\"gold_graph\"])):\n",
    "    head = exp[0][0]\n",
    "    tail = exp[-1][-1]\n",
    "    path = PG.connect_entities(head, tail)\n",
    "    generated_paths_copa.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f49476a-0d83-4976-ae45-9bed8294ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_df[\"generated_graph\"] = generated_paths_copa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def4590-97ac-4299-b39d-7192c6bfb94c",
   "metadata": {},
   "source": [
    "### 3.1.2) ExplaGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "345a5598-a2a7-4d32-8d68-73cf03ad155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2764/2764 [27:29<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "generated_paths_expa = []\n",
    "for i, exp in enumerate(tqdm(exp_df[\"gold_graph\"])):\n",
    "    head = exp[0][0]\n",
    "    tail = exp[-1][-1]\n",
    "    path = PG.connect_entities(head, tail)\n",
    "    generated_paths_expa.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "652cdb84-b81d-446b-9215-548990a5b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df[\"generated_graph\"] = generated_paths_expa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b70674-bb6c-48c9-85ad-a96c84fd9dcc",
   "metadata": {},
   "source": [
    "## 3.2) Add pseudo-random graphs via naive retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93382beb-f0f1-400f-8f60-02ec20935dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_path(belief, argument, model, PR):\n",
    "        '''\n",
    "            Finds paths between concepts indentified in the belief and the argument.\n",
    "            Each path is scored against the original context with cosine similarity using SentenceTransformer.\n",
    "        '''\n",
    "        answers_tmp = argument\n",
    "        q_words = []\n",
    "        answer_words = []\n",
    "        for q in belief.split(\" \"):\n",
    "            if PR.is_entity(q) and q not in eng_stop_words:\n",
    "                q_words.append(q)\n",
    "        for a in argument.split(\" \"):\n",
    "            if PR.is_entity(a) and a not in eng_stop_words:\n",
    "                answer_words.append(a)\n",
    "\n",
    "        paths = []\n",
    "        top_score = 0.0\n",
    "        best_path = \"\"\n",
    "        flag = 0\n",
    "\n",
    "        for q in q_words:\n",
    "            for a in answer_words:\n",
    "                if not q == a:\n",
    "                    path =  PR.get_path(q, a)\n",
    "                    if path != -1: paths.append(path)\n",
    "                        \n",
    "        for path in paths:\n",
    "            str_path = \"\"\n",
    "            for triple in path:\n",
    "                head, rel, tail = triple\n",
    "                try:\n",
    "                    rel = PR.r2t[rel.strip(\"_\")]\n",
    "                except:\n",
    "                    continue\n",
    "                str_path += head + \" \" + rel + \" \" + tail + \" \"\n",
    "            path_emb = model.encode(str_path, convert_to_tensor=True, show_progress_bar=False)\n",
    "            question_emb = model.encode(belief, convert_to_tensor=True, show_progress_bar=False)\n",
    "            score = util.cos_sim(path_emb, question_emb)\n",
    "            if score > top_score:\n",
    "                top_score = score\n",
    "                best_path = path\n",
    "        \n",
    "        if best_path != \"\":\n",
    "            return best_path\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca5ce38d-1b56-4f85-b0ef-1b1410405500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading conceptnet...\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "PR = PathRetriever(\"../data/conceptnet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a777a-baac-44a6-8d5b-123a5217fdf5",
   "metadata": {},
   "source": [
    "### 3.2.1) COPA-SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50721560-386c-4783-856d-59331185b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [08:35,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "random_paths_copa = []\n",
    "for i, (a, b, c) in enumerate(tqdm(zip(copa_df[\"p\"], copa_df[\"a1\"], copa_df[\"a2\"]))):\n",
    "    path = find_best_path(a.lower(), b.lower() + \" \" + c.lower(), model, PR) # Concat a1 and a2\n",
    "    random_paths_copa.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d34e001-fbe9-4492-925b-0e1b63de9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_df[\"retrieved_graph\"] = random_paths_copa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5278d4-342b-4dee-b67e-fd37a4204646",
   "metadata": {},
   "source": [
    "### 3.2.2) ExpaGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aed0e403-3d51-462b-be07-0806d4b9b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2764it [32:17,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "random_paths_expa = []\n",
    "for i, (a, b) in enumerate(tqdm(zip(exp_df[\"belief\"], exp_df[\"argument\"]))):\n",
    "    path = find_best_path(a.lower(), b.lower(), model, PR) # Concat a1 and a2    \n",
    "    random_paths_expa.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "329c617c-46e3-4ad1-8b9a-54c842771cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df[\"retrieved_graph\"] = random_paths_expa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cb803-6519-484c-91d2-f995821446c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4.0 Split and save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882561f9-5600-41a3-a4db-ee40528861ee",
   "metadata": {},
   "source": [
    "### Copa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4702f2ca-461c-42ae-b31f-7fa8a4b3e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_copa, test_copa = train_test_split(copa_df, random_state=1, test_size=0.1)\n",
    "train_copa, val_copa = train_test_split(train_val_copa, random_state=1, test_size=0.1)\n",
    "train_copa.to_csv(\"../data/copa/train_v2.tsv\", sep=\"\\t\")\n",
    "val_copa.to_csv(\"../data/copa/val_v2.tsv\", sep=\"\\t\")\n",
    "test_copa.to_csv(\"../data/copa/test_v2.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea688b-e9ce-4fd7-93cc-cc0f0d3fce72",
   "metadata": {},
   "source": [
    "### ExplaGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae5452b3-37fe-408a-b6a0-1d3b53e83878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_exp, test_exp = train_test_split(exp_df, random_state=1, test_size=0.1)\n",
    "train_exp, val_exp = train_test_split(train_val_exp, random_state=1, test_size=0.1)\n",
    "train_exp.to_csv(\"../data/explagraphs/train_v2.tsv\", sep=\"\\t\")\n",
    "val_exp.to_csv(\"../data/explagraphs/val_v2.tsv\", sep=\"\\t\")\n",
    "test_exp.to_csv(\"../data/explagraphs/test_v2.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a3750-2986-44c1-a9f3-5ecdb9ba53a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
